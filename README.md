# BERT Relation Extraction Demo

This project demonstrates **relation extraction** using a fine-tuned **BERT** model.  
It identifies semantic relationships between entities (e.g., *used_weapon*, *occurred_in*, *handled_by*) from incident-related text data.

---

## Overview

The goal of this project is to extract meaningful **entity relationships** from text, similar to how research papers convert unstructured data (e.g., mass shooting reports) into structured knowledge graphs.

### Example

**Input Sentence:**
> John Doe used a rifle at a school.

**Predicted Output:**
> `John Doe â€” used_weapon â†’ rifle`

---

## Tech Stack

| Component | Description |
|------------|-------------|
| **Python** | Core programming language |
| **PyTorch** | Deep learning backend |
| **Hugging Face Transformers** | BERT fine-tuning & tokenization |
| **Pandas / scikit-learn** | Data preprocessing & evaluation metrics |
| **Matplotlib / NetworkX** | Visualization of extracted relations |

---

## OutPut


---

## Project Structure

```bash
bert_relation_extraction_demo/
â”‚
â”œâ”€â”€ dataset.csv              # Input dataset: sentence, entity1, entity2, relation
â”œâ”€â”€ train.py                 # Fine-tunes BERT model on relation extraction task
â”œâ”€â”€ predict.py               # Interactive CLI for making predictions
â”œâ”€â”€ visualize.py             # Graph visualization of predicted relations
â”œâ”€â”€ evaluate.py              # Computes precision, recall, and F1-score
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .gitignore               # Files excluded from GitHub
â”‚
â”œâ”€â”€ model/                   # Saved trained model (excluded from repo)
â”œâ”€â”€ results/                 # Training results (optional)
â”‚
â”œâ”€â”€ metrics.txt              # Evaluation results summary
â””â”€â”€ relation_graph.png       # Visualization output image


---

## ğŸš€ Setup Instructions

## 1ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate        # Windows


# OR
source venv/bin/activate     # macOS/Linux
---

## 2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

---
## 3ï¸âƒ£ Train the Model

python train.py
This trains the BERT model and saves it in the /model folder.
---
##4ï¸âƒ£ Make Predictions

python predict.py

You can then interactively enter:

Sentence: John Doe used a rifle at a school.
Entity 1: John Doe
Entity 2: rifle
Output:

 Predicted Relation: used_weapon
---
## Visualization
After making a few predictions, run:

python visualize.py
This generates a graph showing all extracted relations.

---
## Example Visualization Output:


(Generated using NetworkX + Matplotlib)

Evaluation Results
Validation Results (sample run)

Relation	Precision	Recall	F1-score	Support
used_weapon	0.44	1.00	0.61	4
occurred_in	0.33	1.00	0.50	1
targeted_location	0.00	0.00	0.00	2
killed_victims	0.00	0.00	0.00	1
motivated_by	0.00	0.00	0.00	1
arrested_by	0.00	0.00	0.00	1
mental_health_issue	0.00	0.00	0.00	3

Accuracy: 38.46%
Macro Avg F1: 0.1593
Weighted Avg F1: 0.2278

ğŸ§© Note: These results are from an early prototype trained on a small, imbalanced dataset.
With more balanced data and 5â€“8 epochs of training, the model performance is expected to improve significantly.

ğŸ¯ Future Improvements
ğŸ“ˆ Increase dataset size for underrepresented relations

ğŸ§© Experiment with BERT variants (e.g., roberta-base, bert-large)

ğŸ§  Add confusion matrix visualization for clearer performance insight

ğŸ”— Integrate Knowledge Graphs for advanced entity relation mapping

ğŸš€ Implement RAG (Retrieval-Augmented Generation) to combine structured + unstructured reasoning

ğŸ‘¨â€ğŸ’» Author
Asad Bukhari
Full Stack Developer & AI Research Enthusiast

ğŸ’¼ Octek | AI + NLP + RAG Pipeline Developer

ğŸŒ Passionate about NLP, Relation Extraction & Knowledge Graphs

ğŸ“§ Contact: asadbukhari612@gmail.com